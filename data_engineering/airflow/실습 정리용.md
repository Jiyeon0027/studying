Celery Executor 사용

GCP에서 Celery Executor를 사용하여 3개의 인스턴스에 Airflow를 분산 구성

1. 인스턴스 구성
   Instance 1: Airflow Webserver + Scheduler (마스터 노드)
   Instance 2: Airflow Worker
   Instance 3: Airflow Worker

   모든 인스턴스에 에어플로우 설치

   ```bash
   # 필요한 패키지 설치
   sudo apt-get update
   sudo apt-get install -y python3-pip postgresql-client redis-tools

   # Airflow 및 의존성 설치
   pip install 'apache-airflow[celery,postgres,redis]'
   ```

2. postgreSQL 과 Redis설정은 어떻게?

   1. 클라우드 SQL, MemoryStore를 사용하는 방법
   2. 마스터 노드에 postgreSQL 설치 후 클라이언트로 공유
      postgres의 user airflow 의 비밀번호 'your_password' 로 설정됨....

   3. redis 마스터 노드에 설치

      bind 0.0.0.0 외부접속 허용 설정
      bind 0.0.0.0 ::1
      redis requirepass : redis7927
      maxmemory 256mb # 메모리 제한 설정
      maxmemory-policy allkeys-lru # 메모리 정책

3. 설정파일 설정
   먼저 airflow db init을 실행해주어야 airflow.cfg 파일이 생김

```python
[core]
# DAG 관련 설정
dags_folder = /home/airflow/airflow/dags
load_examples = False
executor = CeleryExecutor

# DB 연결 설정
sql_alchemy_conn = postgresql+psycopg2://airflow:your_password@localhost:5432/airflow

[celery]
# Redis 연결 설정
broker_url = redis://:your_redis_password@localhost:6379/0
result_backend = db+postgresql://airflow:your_password@localhost:5432/airflow

[webserver]
web_server_host = 0.0.0.0
web_server_port = 8080

[scheduler]
scheduler_heartbeat_sec = 5
```

워커노드의 설정

```python
[core]
dags_folder = /home/airflow/airflow/dags
load_examples = False
executor = CeleryExecutor

# 마스터 노드의 IP 주소 사용
sql_alchemy_conn = postgresql+psycopg2://airflow:your_password@[마스터노드_IP]:5432/airflow

[celery]
# 마스터 노드의 IP 주소 사용
broker_url = redis://:your_redis_password@[마스터노드_IP]:6379/0
result_backend = db+postgresql://airflow:your_password@[마스터노드_IP]:5432/airflow
```

## GCP 명령들

1. gcloud compute ssh [INSTANCE_NAME] --zone=[ZONE]
   -> GCP는 로컬 머신의 SSH 키를 생성하고 GCP 프로젝트에 등록

2. gcloud compute ssh 없이 바로 ssh 접속하고 싶다면

   - ssh 키 위치 확인

     - ~/.ssh/google_compute_engine
     - ~/.ssh/google_compute_engine.pub

     - ssh -i ~/.ssh/google_compute_engine [USERNAME]@[EXTERNAL_IP]
