# Chapter 4. 카프카 컨슈머 : 카프카에서 데이터 읽기

- 토픽을 구독하고 구독한 토픽들로부터 메시지를 받기 위해 `KafkaConsumer`사용

## 4.1 카프카 컨슈머 : 개념

### 컨슈머와 컨슈머 그룹

- 컨슈머 객체를 생성 -> 해당 토픽 구독 -> 메시지를 받아 검사하고 결과를 써야함
- 만약 더 빠른 속도로 토픽에 메시지를 프로듀서가 쓴다면?
  - 컨슈머의 갯수를 확장하여 분할해서 데이터를 읽어와야 함
  - 이를 위해 컨슈머 그룹의 일부로 `카프카 컨슈머`가 동작

<img src="https://velog.velcdn.com/images/tngus3722/post/31de66de-f6f9-4fbd-aeaa-03e821117d49/image.png" alt="카프카 컨슈머 그룹 2" width="300" style="display: block; margin: 0 auto;"><br>

- 컨슈머 그룹에 파티션 수보다 많은 컨슈머를 추가하여 `유휴상태`가 되어 메시지를 받지 못하는 모습

<img src="https://velog.velcdn.com/images/tngus3722/post/7346e2b6-b267-4de2-93ad-0dc392d04c3c/image.png" alt="카프카 컨슈머 그룹 5" width="300" style="display: block; margin: 0 auto;" >

- **컨슈머 추가**: DB 저장 등 지연이 긴 작업으로 인해 일반적으로 컨슈머를 추가하여 분산 처리
- **컨슈머 그룹**: 여러 애플리케이션이 한 토픽을 사용할 때 각각 다른 컨슈머 그룹 생성
  - 성능 저하 없이 카프카 활용 가능

<img src="https://velog.velcdn.com/images/tngus3722/post/5cd2abdc-9c0c-4caf-8737-b7e04fcbed22/image.png" alt="카프카 컨슈머 그룹 5" width="300" style="display: block; margin: 0 auto;" >

### 컨슈머 그룹과 파티션 리벨런스

- 컨슈머 그룹에 컨슈머가 추가되거나 종료되면?

  - 컨슈머에 파티션을 재할당 받아야 함 (`리밸런스`)
  - 따라서 컨슈머들은 토픽의 파티션들에 대한 소유권을 공유
  - `높은 가용성`과 `규모 가변성` 제공

- 조급한 리밸런스 eager rebalance
  - **모든** 컨슈머가 읽기 작업을 멈추고 소유권을 포기 -> 다시 참여 join 후 파티션을 할당 받음
  - 작업이 멈추는 단점
- 협력적 리밸런스 cooperative rebalance

  - 한 컨슈머에게 할당 되어 있던 파티션만을 다른 컨슈머에 재할당
  - 순서
    1. 컨슈머 그룹 리더가 재할당 될것임을 다른 컨슈머에게 통보
    2. 통보받은 컨슈머는 작업을 멈추고 소유권 포기
    3. 새로 할당
  - 장점 : 멈추지 않고 점진적으로 할당 가능

- 어떻게 컨슈머 리밸런싱 시작하는가?
  - 각 컨슈머들은 그룹 코디네이터 역할을 지정받은 해당 컨슈머 그룹의 카프카 브로커에 하트비트를 전송
  - 이를 통해 멤버십과 할당된 파티션에 대한 소유권을 유지
    <img src="https://i.ibb.co/S4rX0q62/image.png" alt="카프카 컨슈머 그룹 5" width="80%" style="display: block; margin: 0" >
  - 만약 하트비트가 전송되지 않으면 죽었다고 판단후 리밸런스 진행

### 정적 그룹 멤버십

- 보통 컨슈머가 갖는 컨슈머 그룹의 멤버로의 자격 : 일시적
- `group.instance.id` 값을 설정하면 정적그룹 멤버십으로 변경되고 컨슈머가 꺼져도 참여할때 다시 파티션을 재할당 받아서 유지 가능
- 컨슈머에 할당된 파티션의 내용물을 사용해서 로컬 상태나 캐시를 유지해야할 때 편리
- 정적멤버의 종료 : `session.timeout.ms`

## 4.2 카프카 컨슈머 생성하기

```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer",
        "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer",
        "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```

- `KafkaConsumer` 인스턴스 생성
- `bootstrap.servers`, `key.deserializer`, `value.deserializer` 지정
- 새로 추가된 속성 : `group.id`- 컨슈머가 속하는 컨슈머 그룹 id를 지정

## 4.3 토픽 구독하기

- 단순히 하나의 토픽이름으로 목록을 생성

```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```

- 정규식을 이용해서 subscribe 하는것도 가능 : 이에 해당하는 토픽에 즉시 리밸런스가 발생

```java
consumer.subscribe(Pattern.compile("test.\*"));
```

## 4.3 폴링 루프

서버에 추가 데이터가 있는지 폴링하는 루프가 컨슈머 API의 핵심

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);

    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n",
            record.topic(), record.partition(), record.offset(), record.key(), record.value());
        int updatedCount = 1;
        if (custCountryMap.containsKey(record.value())) {
            updatedCount = custCountryMap.get(record.value()) + 1;
        }
        custCountryMap.put(record.value(), updatedCount);

        JSONObject json = new JSONObject(custCountryMap);
        System.out.println(json.toString());
    }
}
```

1.  새 컨슈머에서 처음으로 `poll()`을 호출하면 `GroupCoordinator`를 찾아 컨슈머 그룹에 합류 후 파티션을 할당 받음

- 주의 사항 : `max.poll.interval.ms` 에 지정된 시간 이상으로 호출되지 않으면 죽은 것을 간주
- 최대시간이 0 이거나 버퍼 안에 레코드가 준비되어 있으면 즉시 리턴

2.  반환은 레코드들이 저장된 List객체들 -> 루프를 돌아 하나씩 처리
3.  처리가 끝날때는 데이터 저장소에 쓰거나 레코드 갱신

### 스레드 안정성

- 스레드에 동일한 그룹 내에 여러개의 컨슈머를 생성하거나 같은 컨슈머를 다수의 스레드가 안전하게 이용이 불가능
- <mark>하나의 스레드 당 하나의 컨슈머</mark> 가 원칙

방법 1.<br>
스레드를 여러개 띄워 각각의 컨슈머 연결 - java `ExecutorService` 사용해 다수의 스레드를 시작시킴
방법 2. <br>
이벤트를 받아서 큐에 넣는 컨슈머 하나 처리하는 여러개의 워커 스레드 사용

> 이전 `poll(long)` 메서드: 타임아웃 시간보다 더 오래 걸리더라도 Kafka로부터 필요한 메타데이터를 가져올 때까지 블로킹될 수 있었다.<br>
> 새로운 `poll(Duration)` 메서드: 타임아웃 제한을 엄격하게 준수하며, 메타데이터를 기다리지 않는다

## 4.5 컨슈머 설정하기

- `fetch.min.bytes`

  - 레코드를 가져올 때 브로커로부터 받기 원하는 데이터의 최소 바이트 지정.
  - 만일 브로커가 컨슈머로부터 레코드 요청을 받았지만 읽은 레코드들의 양이 fetch.min.bytes보다 작다면 브로커는 더 많은 메시지가 모일 때 까지 기다린다.

- `fetch.max.wait.ms`

  - fetch.min.bytes가 충족되지 못하였을 때 대기하는 시간을 의미한다.
  - 즉 해당 시간이 되었을 때는 fetch.min.bytes가 충족되지 않았어도 데이터를 가져온다.

- `fetch.max.bytes`

  - 컨슈머가 서버로 부터 받은 데이터를 저장하기 위해 사용하는 메모리의 양으 ㄹ 제한
  - 컨슈머가 읽기 작업을 계속 진행하도록 보장

- `max.poll.records`

  - poll()을 호출할때마다 리턴되는 최대 레코드 **갯수** 지정

- `max.partition.fetch.bytes`

  - 서버가 파티션별로 리턴하는 최대 바이트 수를 결정
  - 사용이 어려우므로 fetch.max.bytes 사용을 강력히 권장

- `session.timeout.ms` `heartbeat.interval.ms`

  - 그룹 코디네이터에게 하트비트를 보내지 않은 채 `session.timeout.ms` 가 지나면 죽은 것으로 간주
  - 하트비트의 주기 설정 : `heartbeat.interval.ms`
  - 보통 하트비트의 주기의 3배가 세션타임아웃 시간

- `max.poll.interval.ms`

  - 컨슈머가 폴링하지 않고도 죽은 것으로 판정되지 않을 수 있는 최대 시간
  - 하트비트를 보내는데도 다른 메인 스레드의 데드락으로 인해 처리되지 않는 것처럼 여러 영향이 있음 -> 안전장치로 이용

- `default.api.timeout.ms`

  - 모든 컨슈머 api 호출에 적용되는 타임아웃 값 (기본 1분)

- `request.timeout.ms`

  - 브로커로부터 컨슈머가 기다릴 수 있는 응답 최대시간

- `auto.offset.reset`

  - 컨슈머가 예전에 오프셋을 커밋한 적이 없거나 커밋된 오프셋이 유효하지 않을깨 파티션을 읽기 시작할때의 작동
  - 기본 : latest - 가장 최신의 레코드
  - earliest - 제일 처음의 레코드부터

- `enable.auto.commit`

  - 컨슈머가 자동으로 오프셋을 커밋할지의 여부
  - 기본 : true

- `partition.assignment.strategy`

  - 컨슈머 파티션 할당 전략
  - Range : 연속된 그룹으로 나누어 할당
  - RoundRobin : 모든 파티션을 가져다가 순차적으로 하나씩 컨슈머에 할당
  - Sticky : 가능한 파티션을 균등하게 할당 / 리밸런스 발생시 가능한 많은 파티션이 같은 컨슈머에 할당되도록 함으로써 오버헤드 최소화
  - Cooperative Sticky : Sticky와 비슷하지만 협력적 리밸런싱 기능 지원

- `client.id`

  - 클라이언트 식별

- `client.rack`

  - 가까운 랙에서 읽어올 수 있도록 하는 최적의 레플리카 선택 지정

- `group.instance.id`

  - 정적그룹 멤버십 기능을 위한 설정

- `receive.buffer.bytes` , `send.buffer.bytes`

  - 데이터를 읽거나 쓸 때 상요하는 TCP 수신 및 수신버퍼의 크기
  - -1 -> 운영체제 기본값

- `offsets.retention.minutes`
  - 컨슈머그룹이 비어있게 되었을 때 오프셋 값을 저장할 기간

## 4.6 오프셋과 커밋

- 오프셋 커밋 : 파티션에 현재 위치를 업데이트 하는 작업
  - `__consumer_offsets` 이라는 특수 토픽에 각 파티션별로 커밋된 오프셋을 업데이트
  - 기본 : poll()이 리턴한 마지막 오프셋 바로 다음 오프셋을 커밋하는 것이 기본적 작동
  - 리밸런싱이 발생하게 되면?
    - 만약 커밋된 오프셋이 클라이언트가 처리한 마지막 오프셋보다 작을 경우 마지막으로 처리된 오프셋과 커밋된 오프셋 사이의 메시지들은 두번 처리하게 됨
      ![재처리된 메시지](https://velog.velcdn.com/images/tngus3722/post/2c797732-c515-4fce-831a-3296d51b2bc5/image.png)
    - 만약 커밋된 오프셋이 처리중인 이벤트보다 클 경우 마지막으로 처리된 오프셋과 커밋된 오프셋 사이의 모든 메시지들은 누락
      ![누락된 메시지](https://velog.velcdn.com/images/tngus3722/post/3edeba4f-78ec-4378-9708-204bafd9e676/image.png)

### 1. 자동 커밋

컨슈머가 대신 커밋하도록 하는 방법

- enable.auto.commit = true 설정 시 5초에 한번 poll()을 통해 받은 메시지 중 마지막 메시지의 오프셋을 커밋
- 만약 자동 커밋후 3초뒤에 크래시가 발생한다면?
  - 커밋 오프셋은 3초 전 것이므로 중복이 발생 가능

### 2. 현재의 오프셋 커밋

- `enable.auto.commite = false` 설정 후 애플리케이션이 명시적 커밋할때만 하도록 함
- `commitSync()` 를 이용해 리턴된 마지막 오프셋을 커밋
  - 모든 레코드가 처리되기 전 크래시되면 브로커는 이미 보낸 상황이기 때문에 누락 발생 가능
  - 레코드가 처리되는 중간에 크래시가 난 경우 메시지 배치의 맨 앞 레코드 부터 리밸런스 시작 시점까지의 모든 레코드들은 두번 처리

```java
Duration timeout = Duration.ofMillis(100);
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);
    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n",
            record.topic(), record.partition(), record.offset(), record.key(), record.value());
    }
    try {
        consumer.commitSync(); // 해당 배치의 마지막 오프셋을 커밋
    } catch (CommitFailedException e) {
        log.error("commit failed", e);
    }
}
```

### 3. 비동기적 커밋

- 수동 커밋의 단점 : 브로커가 커밋 요청에 응답할때 까지 애플리케이션이 블록되고 처리량을 제한
- 해결 : `commitAsync()` 를 사용하여 비동기 처리
  - 실패해도 재시도를 하지 않는다는 단점
- 오프셋 커밋을 <mark>올바른 순서로 커밋</mark>하는 문제의 복잡성과 중요성
  - commitAsync() 에도 브로커가 보낸 응답을 받았을때 호출되는 콜백을 지정할 수 있는 옵션이 있음
  - 예시 : 로깅, 에러 집계

```java
Duration timeout = Duration.ofMillis(100);

while(true){
  ConsumerRecords<string, String> records = consumer.poll(timeout);
  for(ConsumerRecord<String, String> record : records){
    System.out.printf("topic = %s, partition = %d, offset = %d, consumer =%s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
    }
  try {
    consumer.commitAsync(new OffsetCommitCallback() {
      @Override
      public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception exception) {
        if (e!=null) {
          log.error("commit failed", e); // 오류 처리(비동기 콜백)
        }
      }
    });
  })); // 해당 배치의 마지막 오프셋을 커밋

}
```

> 비동기적 커밋 재시도 <br>
> 순차적으로 단조증가하는 번호를 사용하여 비동기적 커밋을 재시도할때 순서를 맞출 수 있음. 그리고 재시도요청을 보낼 준비가 되었을때 번호를 비교

### 4. 동기적 커밋과 비동기적 커밋을 함계 사용

- 보통 컨슈머가 닫기전, 리밸런스 전 마지막 커밋이라면 성공여부를 추가로 확인해야함.
- `commitSync()` 와 `commitAsync()`를 함께 사용해야함

```java
Duration timeout = Duration.ofMillis(100);
try{
  while(true){
    ConsumerRecords<string, String> records = consumer.poll(timeout);
    for(ConsumerRecord<String, String> record : records){
      System.out.printf("topic = %s, partition = %d, offset = %d, consumer =%s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
      }
      consumer.commitAsync()
    }
    commitSync() // -> 종료시에 커밋싱크를 날려서 커밋성공시까지 재시도!!!
} catch(CommitFailedException e){
  log.error("commit failed", e);
} finally{
  consumer.close();
}
```

### 5. 특정 오프셋 커밋하기

- 더 자주 커밋하기 위해서 사용

  - commitSync(), commitAsync()를 호출할 때 커밋하고자 하는 파티션과 오프셋 맵을 지정가능

  ```java
  Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();
  //오프셋을 추적하기 위한 맵
  int count = 0;

  Duration timeout - Duration.ofMillis(100);

  while(true){
    ConsumerRecords<String, String> records = consumer.poll(timeout);
    for(ConsumerRecord<String, String> record : records){
      System.out.printf("topic = %s, partition = %d, offset = %d, customer=%s, country=%s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());

      currentOffsets.put(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1, "no metadata")); // 다음번에 처리할 것으로 예상되는 오프셋을 업데이트

      if (count %1000 == 0){
        consumer.commitAsync(currentOffsets, null);//1000개의 레코드마다 현재 오프셋을 커밋
      }
      count++;
    }
  }

  ```

## 4.7 리밸런스 리스너

- 컨슈머는 종료하기 전이나 리밸런식이 시작되기전에 `cleanup`을 진행해주어야함
- subscribe()를 호출할때 ConsumerRebalanceListener를 전달해주면 됨

- `public void onPartitionsAssigned(Collection<TopicPartition> partitions)`

  - 파티션이 컨슈머에게 재할당된 후, 하지만 컨슈머가 메시지를 읽기 시작하기 전에 호출됨
  - 파티션과 함께 사용할 상태를 적재하거나 필요한 오프셋을 탐색 등

- `public void onPartitionsRevoked(Collection<TopicPartition> partitions)`

  - 컨슈머가 할당 받았던 파티션이 할당 해제될 때 호출됨
  - 조급한 리밸런스 시 : 리밸런스가 시작되기 전에
  - 협력적 리밸런스 시 : 리밸런스가 완료될 때 할당 해제되어야 할 파티션들에 대해

- `public void onPartitionsLost(Collection<TopicPartition> partitions)`
  - 협력적 리밸런스 시 : 할당된 파티션이 리밸런스 알고리즘에 의해 해제되기 전에 다른 컨슈머에 먼저 할당된 예외적인 상황에서
  - 파티션과 함께 사용되었던 상태나 자원들 정리
  - 예외적 상횡이 아닌경우 `onPartitionsRevoked`호출

## 4.8 특정 오프세의 레코드 읽어오기

- 기본 : 마지막으로 커밋된 오프셋에서 poll()
- 맨앞에서 읽기 : `seekToBeginning(Collection<TopicPartition>)`
- 새로 들어온 것부터 읽기 : `seekToEnd(Collection<TopicPartition>)`
- 특정 시각으로 돌아가기 : 오프셋을 재설정

```java
Long oneHourEarlier = Instant.now().atZone(ZoneId.systemDefault()).minus(1, ChronoUnit.HOURS).toEpochMilli();)

Map<TopicPartition, Long> partitionTimestampMap = consumer.assginment().stream()
  .collect(Collectors.toMap(tp->tp, tp-> oneHourEarlier));
  //컨슈머에 할당된 모든 파티션에 대해 컨슈머를 되돌리고자 하는 타임스탬프 값을 담은 맵 생성
Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionTimestampMap);
// 브로커에 요청을 보내어 타임스탬프 인덱스에 저장된 오프셋을 리턴받음

for (Map.Entity<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()){
  TopicPartition tp = entry.getKey();
  OffsetAndTimestamp offsetAndTimestamp = entry.getValue();
  consumer.seek(tp, offsetAndTimestamp.offset());// 오프셋을 재설정
}
```

## 4.9 폴링 루프를 벗어나는 방법

- 다른스레드에서 `consumer.wakeup()` 호출 - <mark>안전!!</mark>
- 메인스레드에서 컨슈머 루프가 돌고 있다면 `ShutdownHook`을 사용
- 컨슈머를 종료하기 전에 `consumer.close()`를 실행해 리소스를 정리해줌

## 4.10 디시리얼라이저

- 같은 데이터 타입의 Serializer, Deserializer를 묶어 놓은 클래스 : `org.apache.kafka.common.serialization.Serdes`
- 카프카 프로듀서에서 커스텀 타입을 직렬화 하는 방법을, 카프카 컨슈머에서 커스텀 타입을 역직렬화 하는 방법을 이해

### 커스텀 디시리얼라이저

```java
  import org.apache.kafka.common.errors.SerializationException;
  import java.nio.ByteBuffer

  public class CustomerDeserializer implements Deserializer<Customer> {
    @Override
    public void configure(Map<String, ?> configs, boolean isKey) {
    }

    @Override
    public Customer deserialize(String topic, byte[] data) {
      int id;
      int nameSize;
      String name;
      try {
        if (data == null) {
          return null;
        }
        if (data.length <8) {
          throw new SerializationException("Size of data received by CustomerDeserializer is shorter than expected");
        }

        ByteBuffer buffer = ByteBuffer.wrap(data);
        id = buffer.getInt();
        nameSize = buffer.getInt();

        byte[] nameBytes = new byte[nameSize];
        buffer.get(nameBytes);
        name = new String(nameBytes, "UTF-8");

        return new Customer(id, name);
      } catch (Exception e) {
        throw new SerializationException("Error when deserializing byte[] to Customer");
      }
    }

    @Override
    public void close() {
      }
  }
```

- 하지만 역시 권장되지 않고 json, Thrift, Protobuf, Avro 와 같은 표준 메시지 형식을 이용하는 것이 더 좋은 선택

### Avro 디시리얼라이저 사용하기

```java
Duration timeout = Duration.ofMillis(100);

Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "io.confluent.kafka.serializers.KafkaAvroDeserializer");
props.put("schema.registry.url", "http://schema-registry:8081");//스키마 레지스트리 저장된 곳

KafkaConsumer<String, Customer> consumer = new KafkaConsumer<String, Customer>(props);//카프카 컨슈머 지정

while (true) {
    ConsumerRecords<String, Customer> records = consumer.poll(timeout);//컨슈머로 레코드 벨류 지정

    for (ConsumerRecord<String, Customer> record : records) {
      System.out.printIn("Current customer name is :" + record.value().getName());
    }
    consumer.commitSync();
}

```

## 4.11 독립 실행 컨슈머 : 컨슈머 그룹없이 컨슈머를 이용해야 하는 이유와 방법

- 예를 들어 하나의 컨슈머가 토픽의 모든 파티션으로부터 데이터를 읽어와야 하거나 특정 파티션으로부터 데이터를 읽어와야 하는 경우
- 특정 토픽을 구독 하거나 파티션을 지정할당 하기 (둘 다는 불가)

```java
Duration timeout = Duration.ofMillis(100);
LList<PartitionInfo> partitionInfos = consumer.partitionsFor("customerCountries");

if (partitionInfos !=null){
  for (PartitionInfo partitionInfo : partitionInfos){
    partitions.add(
      new TopicPartition(partitionInfo.topic(), partitionInfo.partition()));
  }
  consumer.assign(partitions);
  //카프카가 해당 토픽의 파티션에 대해 할당받기

  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);

    for (ConsumerRecord<String, String> record : records) {
      System.out.printf("topic = %s, partition = %s, offset = %d, cumstomer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
    }
    consumer.commitSync();

  }
}
```

- 리밸런스가 안된다는점
- 파티션이 추가되는지 아닌지를 항상 확인해주어야 함 -> `consumer.partitionsFor()`
