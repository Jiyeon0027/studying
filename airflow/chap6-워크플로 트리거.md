# Chapter 6. ì›Œí¬í”Œë¡œ íŠ¸ë¦¬ê±°

- íŠ¹ì • ì¡°ê±´ì„ ì„¼ì„œì— ë§Œì¡±í•˜ë„ë¡ ëŒ€ê¸°
- ì„œë¡œ ë‹¤ë¥¸ DAGì˜ íƒœìŠ¤í¬ ê°„ ì˜ì¡´ì„ ì„¤ì •
- CLI ë° REST API ë¥¼ í†µí•´ ì›Œí¬í”Œë¡œ ì„¤ì •

## 6.1 ì„¼ì„œë¥¼ ì‚¬ìš©í•œ í´ë§ ì¡°ê±´

#### ğŸ“ ë¬¸ì œ ìƒí™©

ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë¹„ì •ê·œì ì¸ ì‹œê°„ì— ë„ì°©í•˜ëŠ” ê²½ìš°:

> ê¸°ì¡´ ë¬¸ì œì 
> ì§€ì •ëœ ì‹œê°„ì— ì‹œì‘í•˜ë„ë¡ í–ˆì„ ë•Œ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ë•Œê¹Œì§€ì˜ ëŒ€ê¸°ì‹œê°„ì´ ë§ì´ ì†Œìš”ë¨

#### âœ¨ í•´ê²°ë°©ì•ˆ

Airflow ì˜¤í¼ë ˆì´í„°ì˜ íŠ¹ìˆ˜íƒ€ì… ì„¼ì„œ(sensor)ë¥¼ ì‚¬ìš©

- ì„¼ì„œëŠ” íŠ¹ì •ì¡°ê±´ì´ `true` ì¸ì§€ë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ì¸í•˜ê³  `true` ë¼ë©´ ì„±ê³µ
- falseì¸ ê²½ìš°, ìƒíƒœê°€ `true`ê°€ ë ë•Œ ê¹Œì§€, íƒ€ì„ì•„ì›ƒì´ ë ë•Œ ê¹Œì§€ ê³„ì† í™•ì¸

#### ğŸ’» êµ¬í˜„ ì˜ˆì‹œ

```python
from airflow.sensors.filesystem import FileSensor

wait_for_supermarket_1 = FileSensor(
    task_id="wait_for_supermarket_1"
    filepath="/data/supermarket1/data.csv"
)
```

- íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (`true`/`false`)
- ì„¼ì„œë„ ì˜¤í¼ë ˆì´í„°ì´ë¯€ë¡œ íƒ€ì„ì•„ì›ƒ ì„¤ì • ê°€ëŠ¥
- ì•½ 1ë¶„ì— í•œ ë²ˆì”© íŒŒì¼ í™•ì¸ (`í¬í‚¹/Poking`)
- `poke_interval` ì¸ìˆ˜ë¡œ ê°„ê²© ì¡°ì • ê°€ëŠ¥
- `Task Log`ì—ì„œ ì„¼ì„œì˜ ì¶œë ¥ ë‚´ìš© í™•ì¸ ê°€ëŠ¥
- DAGì˜ ì‹œì‘ì‹œê°„ì„ ë°ì´í„°ê°€ ë„ì°©í•˜ëŠ” ê²½ê³„ì˜ ì‹œì‘ë¶€ë¶„ì— ë°°ì¹˜í•¨

### ì‚¬ìš©ì ì§€ì • ì¡°ê±´ í´ë§

#### ğŸ“ ë¬¸ì œ ìƒí™©

ì™€ì¼ë“œ ì¹´ë“œë¥¼ í˜•ì‹ì„ ì´ìš©í•´ ì—¬ëŸ¬ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê²Œ ë˜ë©´ ì›í•˜ì§„ ì•ŠëŠ” ë°ì´í„°ì—ë„ True ê°’ì„ ë°˜í™˜í•  ìˆ˜ ìˆìŒ

#### âœ¨ í•´ê²°ë°©ì•ˆ

ìµœì¢… ì—…ë¡œë“œ íŒŒì¼ì€ \_SUCCESS ë¼ëŠ” ì ‘ë¯¸ì‚¬ë¥¼ ë¶™ì´ê¸°ë¡œ í•©ì˜ í•˜ì˜€ìŒ
-> PythonSensorë¥¼ ê·¸ë¦¬ê³  Callableì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„

```python
from pathlib import Path
from airflow.sensors.python import PythonSensor

def _wait_for_supermarket(supermarket_id):
    supermarket_path = Path("/data/"+supermarket_id)
    data_files=supermarket_path.glob("data-*.csv")
    success_file=supermarket_path / "_SUCCESS"
    return data_files and success_file.exists()

wait_for_supermarket_1 = PythonSensor(
    task_id="wait_for_supermarket_1",
    python_callable=_wait_for_supermarket,
    op_kwargs={"supermarket_id":"supermarket1"}.
    dag=dag
)
```

### ì›í™œí•˜ì§€ ì•ŠëŠ” íë¦„ì˜ ì„¼ì„œì²˜ë¦¬

#### ğŸ“ ë¬¸ì œ ìƒí™©

ë§Œì•½ ë°ì´í„°ê°€ ë”ì´ìƒ ì œê³µë˜ì§€ ì•ŠëŠ”ë‹¤ë©´? <br>
ë‹¤ë¥¸ ì˜¤í¼ë ˆì´í„°ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì‹¤íŒ¨í•  ê²ƒ (ìµœëŒ€ì‹œê°„ì„ ì´ˆê³¼í•˜ëŠ” ì„¼ì„œì´ê¸° ë•Œë¬¸)  
ë³´í†µì„¼ì„œì˜ íƒ€ì„ì•„ì›ƒì€ 7ì¼ë¡œ ë§Œì•½ DAGê°€ í•˜ë£¨ì— í•œë²ˆ ì‹¤í–‰ëœë‹¤ë©´ ì ì  ì¤‘ì²©ë˜ì–´ ì„¼ì„œ ë°ë“œë¡ì˜ ê°€ëŠ¥ì„±

#### âœ¨ í•´ê²°ë°©ì•ˆ

ì‹¤í–‰í…ŒìŠ¤í¬ ìˆ˜ì˜ ì œí•œ

```python
Dag = DAG(
    Dag_id="couponing_app",
    Start_date=datetime(2019,1,1),
    Schedule_interval="0 0 * * *",
    Concurrency=50, #->ë™ì‹œì— 50ê°œì˜ íƒœìŠ¤í¬ ì‹¤í–‰ì„ í—ˆìš©
)
```

#### ğŸ“ ë¬¸ì œ ìƒí™©

ì„¼ì„œ ë°ë“œë¡ : ìœ„ì˜ ì„¼ì„œë¥¼ íƒœìŠ¤í¬ ì¡°ê±´ì´ trueê°€ ë ë•Œ ê¹Œì§€ ë‹¤ë¥¸ íƒœìŠ¤í¬ê°€ ëŒ€ê¸°í•˜ê²Œ ë˜ë¯€ë¡œ ëª¨ë“  ìŠ¬ë¡¯ì´ ë°ë“œë¡ ìƒíƒœê°€ ë¨

#### âœ¨ í•´ê²°ë°©ì•ˆ

ì„¼ì„œë¥¼ `poke` ë˜ëŠ” `reschedule` modeë¡œ ì¸ìˆ˜ ì„¤ì •ê°€ëŠ¥ - `defualt: poke`
poke ëª¨ë“œ : ì„¼ì„œ íƒœìŠ¤í¬ê°€ ì‹¤í–‰ì¤‘ì¸ ë™ì•ˆ íƒœìŠ¤í¬ ìŠ¬ë¡¯ì„ ì°¨ì§€í•˜ì—¬ ìµœëŒ€ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì°¨ë‹¨  
reschedule ëª¨ë“œ : í¬í¬ ë™ì‘ì„ ì‹¤í–‰í• ë•Œë§Œ ìŠ¬ë¡¯ì„ ì°¨ì§€í•¨

## 6.2 ë‹¤ë¥¸ DAGì„ íŠ¸ë¦¬ê±° í•˜ê¸°

ì•ì— ì—¬ëŸ¬ê°œì˜ DAG ê°€ ìˆê³  ê·¸ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆì„ë•Œ ì‹¤í–‰í•˜ë„ë¡ í•˜ëŠ” create_metrics ë¼ëŠ” íƒœìŠ¤í¬ê°€ ìˆì„ë•Œ ì´ëŠ” ë¶„í•  ê°€ëŠ¥í•˜ë‹¤.  
íƒœìŠ¤í¬ë¥¼ ëª¨ë‘ ë³µì œ í•˜ê³  ë” ë§ì€ ë°˜ë³µ íƒœìŠ¤í¬ë¥¼ ë°œìƒì‹œí‚´

ê±°ì˜ ë¹„ìŠ·í•œ ê¸°ëŠ¥ì˜ íƒœìŠ¤í¬ ë°˜ë³µì„ í”¼í•˜ëŠ” í•œê°€ì§€ ì˜µì…˜ì€ ê° DAGë¥¼ ì—¬ëŸ¬ê°œì˜ ì‘ì€ DAGë¡œ ë¶„í• í•˜ì—¬ ê° DAGê°€ ì¼ë¶€ ì›Œí¬ í”Œë¡œë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒ  
ì¥ì  : ë‹¨ì¼ DAGì—ì„œ ì—¬ëŸ¬ íƒœìŠ¤í¬ë¥¼ ë³´ìœ í•˜ì§€ ì•Šê³  DAG1ì´ DAG2ë¥¼ ì—¬ëŸ¬ë²ˆ í˜¸ì¶œ í•  ìˆ˜ ìˆìŒ

```python
from pathlib import Path

import airflow.utils.dates
from airflow import DAG
from airflow.operators.dummy import DummyOperator
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.sensors.python import PythonSensor

dag1 = DAG(
    dag_id="listing_6_04_dag01",
    start_date=airflow.utils.dates.days_ago(3),
    schedule_interval="0 16 * * *",
)
dag2 = DAG(
    dag_id="listing_6_04_dag02",
    start_date=airflow.utils.dates.days_ago(3),
    schedule_interval=None,
)


def _wait_for_supermarket(supermarket_id_):
    supermarket_path = Path("/data/" + supermarket_id_)
    data_files = supermarket_path.glob("data-*.csv")
    success_file = supermarket_path / "_SUCCESS"
    return data_files and success_file.exists()


for supermarket_id in range(1, 5):
    wait = PythonSensor(
        task_id=f"wait_for_supermarket_{supermarket_id}",
        python_callable=_wait_for_supermarket,
        op_kwargs={"supermarket_id_": f"supermarket{supermarket_id}"},
        dag=dag1,
    )
    copy = DummyOperator(task_id=f"copy_to_raw_supermarket_{supermarket_id}", dag=dag1)
    process = DummyOperator(task_id=f"process_supermarket_{supermarket_id}", dag=dag1)
    trigger_create_metrics_dag = TriggerDagRunOperator(
        task_id=f"trigger_create_metrics_dag_supermarket_{supermarket_id}",
        trigger_dag_id="listing_6_04_dag02",
        dag=dag1,
    )
    wait >> copy >> process >> trigger_create_metrics_dag

compute_differences = DummyOperator(task_id="compute_differences", dag=dag2)
update_dashboard = DummyOperator(task_id="update_dashboard", dag=dag2)
notify_new_data = DummyOperator(task_id="notify_new_data", dag=dag2)
compute_differences >> update_dashboard
```

ì´ë•Œ TriggerDagRunOperatorì˜ trigger_dag_idì¸ìˆ˜ì— ì œê³µë˜ëŠ” ë¬¸ìì—´ì€ íŠ¸ë¦¬ê±°í•  DAGì˜ dag_id ì™€ ì¼ì¹˜í•´ì•¼í•¨.  
-> ìƒì„¸ë‚´ì—­ì„ í†µí•´ íŠ¸ë¦¬ê±°ê°€ ë˜ì—ˆëŠ”ì§€ ì•ˆë˜ì—ˆëŠ”ì§€ í™•ì¸ì´ ê°€ëŠ¥í•¨

schedule\_\_ : ìŠ¤ì¼€ì¤„ë˜ì–´ DAG ì‹¤í–‰ì´ ì‹œì‘ë˜ì—ˆìŒì„ ë‚˜íƒ€ëƒ„  
backfill\_\_ : ë°±í•„ í…ŒìŠ¤í¬ì— ì˜í•´ DAG ì‹¤í–‰ì´ ì‹œì‘ë˜ì—ˆìŒì„ ë‚˜íƒ€ëƒ„  
manual\_\_ : ìˆ˜ë™ìœ¼ë¡œ DAG ì‹¤í–‰ì´ ì‹œì‘ë˜ì—ˆìŒì„ ë‚˜íƒ€ëƒ„

### TriggerDagRunOperatorë¡œ ë°±í•„ ì‘ì—…

ì¼ë¶€ ë¡œì§ì„ ë³€ê²½í•˜ê³  ë³€ê²½ëœ ë¶€ë¶„ë¶€í„° DAGë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ë ¤ë©´?  
ë‹¨ì¼ DAGì—ì„œëŠ” íƒœìŠ¤í¬ì˜ ìƒíƒœë¥¼ ì‚­ì œí•˜ë©´ ë¨
ë˜ ë‹¤ë¥¸ DAG ì•ˆì—ì„œ TriggerDagRunOperatorì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ëŠ” ì§€ì›Œì§€ì§€ ì•Šê³  ìƒˆ DAG ì‹¤í–‰ì„ íŠ¸ë¦¬ê±° í•¨

```mermaid
graph TD
    A[DAG A<br/><small>ì›ë³¸ ë°ì´í„° ì²˜ë¦¬</small>]
    B[TriggerDagRunOperator]
    C[DAG B<br/><small>ë³€ê²½ëœ ë¡œì§ìœ¼ë¡œ ì¬ì²˜ë¦¬</small>]

    A --> B --> C
```

### ë‹¤ë¥¸ DAGì˜ ìƒíƒœë¥¼ í´ë§í•˜ê¸°

ì—¬ëŸ¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ DAGì„ íŠ¸ë¦¬ê±° í•˜ëŠ” í•˜ë‚˜ì˜ DAGì˜ TriggerDagRunOperatorë¥¼ ì‚¬ìš© ê°€ëŠ¥

```mermaid
graph TD
    etl1(DAG1) --> DAG4
    etl2(DAG2) --> DAG4
    etl3(DAG3) --> DAG4
```

ìœ„ì™€ ê°™ì€ ê²½ìš° DAGê°„ì˜ ì˜ì¡´ì„±ì„ ê´€ë¦¬í•´ì•¼í•¨

HOW? ë‹¤ë¥¸ DAGì—ì„œ íƒœìŠ¤í¬ ìƒíƒœë¥¼ í¬í¬í•˜ëŠ” ì„¼ì„œì¸ `ExternalTaskSensor`ë¥¼ ì ìš©

ExternalTaskSensorì˜ ê²½ìš° ì •í™•íˆ ë™ì¼í•œ ì‹¤í–‰ ë‚ ì§œë¥¼ ê°€ì§„ íƒœìŠ¤í¬ì— ëŒ€í•œ ì„±ê³µë§Œ í™•ì¸í•¨  
 -> ìŠ¤ì¼€ì¤„ ê°„ê²©ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš° ExternalTaskSensorê°€ ë‹¤ë¥¸ íƒœìŠ¤í¬ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ offsetì„ ì„¤ì • ê°€ëŠ¥í•¨

- `external_dag_id`: ëª¨ë‹ˆí„°ë§í•  DAG ID
- `external_task_id`: ëª¨ë‹ˆí„°ë§í•  íƒœìŠ¤í¬ ID
- `allowed_states`: í—ˆìš©ë˜ëŠ” íƒœìŠ¤í¬ ìƒíƒœ
- `execution_delta`: ì‹¤í–‰ ì‹œì  ì°¨ì´
- `timeout`: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„

## REST/CLIë¥¼ í†µí•´ ì›Œí¬í”Œë¡œ ì‹œì‘í•˜ê¸°

Airflow CLIë¥¼ ì‚¬ìš©í•˜ì—¬ DAGë¥¼ íŠ¸ë¦¬ê±° í• ë•Œ ì™¸ë¶€ì—ì„œ íŠ¸ë¦¬ê±° ë˜ì—‡ìŒì„ ì•Œë¦¬ëŠ” `__manual` í‘œì‹œ

```cli
airflow dags trigger dag1
airflow dags trigger -c '{"supermarket_id":1}' dag1
```

REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë¦¬ê±° í•˜ì—¬ë„ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
